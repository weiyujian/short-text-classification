1.标注训练集
2.文本预处理
	2.0粗处理：过滤长问句，重复问句，无标签问句；细处理：全半角转换，大小写转换
	2.1分词 获取词和词性信息
	2.2去停用词
	2.3特殊词语泛化（人名泛化，数字泛化，业务名称泛化）
	2.4增加bi-gram和skipgram特征（讨论 篮球 不能 发言 bi-gram：-》讨论_篮球 篮球_不能 不能_发言；skipgram：讨论|篮球 讨论|不能 讨论|发言 篮球|不能 篮球|发言 不能|发言）
	2.5交叉熵特征选择（选择前40%重要的特征）
3.特征提取
	特征权重通过tf-idf计算得到（过滤词频低于2的）
4.文本表示
	词袋模型表示文本（总共80w，特征选择后大概还剩19w），通过稀疏矩阵表示（词id：词权重）
5.训练svm分类器
	svm是解决二分类问题的，本身不能解决多分类，需要用trick的方法
	5.1 one-vs-rest
		一对多的方法针对每一个类别训练一个二分类，当前训练的类别为正类，其余所有类别作为负类，有k个类别就要训练k个分类器
		每个类别都输出0或1，最后输出1的类别就是所属类别
		存在问题：可能输出多个1
	5.2 one-vs-one（我们模型所用方法）
		一对一的方法每次随机选两个类出来作为正负类，这样就有k(k-1)/2种情况，训练k(k-1)/2个分类器，预测的时候，这k(k-1)/2
		个分类器依次预测是否属于这两类中的一类，最后投票得到类别最高的那个类
		存在的问题：存在不属于任何一类的时候，即投票出来每个类占的票数都一样多